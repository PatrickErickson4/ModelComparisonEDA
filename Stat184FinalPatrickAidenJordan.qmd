---
title: "Stat184Final"
author: "Patrick Erickson, Aiden Shindel, Jordan Brophy"
format: pdf
editor: visual
csl: mla.csl
---

# Logistic Regression Analysis for Basketball Teams: Can we Create a Robust and Parsimonious Model to Predict if one Basketball Team will Win over Another?

## Introduction

### Intuition Behind the Choice of Data Set

In basketball, a number of statistics can be used in order to predict the winner of a game. For instance, a team's field goal percentage often correlates to the number of points that a team will score in any given game. Therefore, we decided the main focus of our project: **to create a robust, interpretable model that is able to accurately predict the winning team in any case of a given match.** In order to be able to perform this kind of analysis, we must first find a data set that fits the parameters of the following:

-   The data set must be large to be able to test accurately.
-   The data set has meaningful predictors are practically relevant to our test case.
-   The data set contains a binary-interpretable winning/losing team variable (to train and test on)
-   The data set follows **F.A.I.R** and **C.A.R.E** principles.

We ultimately landed on the *NCAA Regular Season Basketball Dataset* by Nate Duncan (Kaggle), due to its extremely high case to variable ratio (90902:40), the fact that the data set had many predictors that would practically contribute to the winning or losing of a team, and that it had included a winning and losing team, which is our testing parameter.

### Ethical Considerations in the Choice of our Data Set

In order to ensure the ethical feasibility of the data set, we also scrutinized our selection to follow the **F.A.I.R** and **C.A.R.E** principles as discussed in class.

Since we had obtained our data from the open-source data hub Kaggle, we can ensure that anyone can **find** and **access** this data set through Kaggle's use guidelines, stating for a free distribution of data sets that are published for public use to practice ML or data analysis on. The data is also highly versatile, taking a csv format. This is one of the most **interoperable** formats there are for data sets, especially for our use-case in R, where reading in a csv is already built into the base. Lastly, the data set can be **reused** for multiple types of data analysis, and will always remain relevant for its time period.

In terms of **collective benefit**, the data set contributes to an overall understanding of basketball without harming any individuals or teams, due to the fact that it is simply raw data. Secondly, as I had stated the author's name, there is clearly ownership over the data set, showing proper **Authority to Control**. Since proper attributions are maintained, it also falls under the **Responsibility and Ethics** guidelines of the C.A.R.E principles.

## Approach

Our main goal is to be able to predict if a team will win or lose based on the statistical metrics given by the data set. Given that this is a binary classification, we can utilize **logistic regression** as a valid means of predicting a win or loss.

### Introduction to Logistical Regression

Logistical regression is a form of regression analysis in which, unlike normal regression where $\hat{\beta}_{MLE}$ (the regression coefficient) be used to explain a direct linear relationship between two variables (conventionally represented as $x_i^T\hat{\beta} + \epsilon_i$ in multiple linear regression), we have such that a logistic regression model is a regression model that can be represented as the log of the odds, or functionally, $$log(\frac{\theta_i}{1-\theta_i}) = x_i^T\hat{\beta}=logit(\theta_i)$$

We can obtain the odds of any one team winning or losing by exponentiating $logit(\theta_i)$, where $\hat\beta$ is fixed and $x_i$ is any valid input of a vector of statistics. This will give us some probability of a team winning based on all the statistical metrics we initially input based on the functional form $\theta_i = logit^{-1}(x_i^T\hat{\beta})$ . We then have some sort of prediction threshold, where we "predict" whether a team will win or lose based on said threshold. This is therefore a possible solution to our proposed question, where we wish to determine the binary probability of a win or a loss (this is our respective $\theta_i$ in terms of the logistic regression model) based on some combination of the factors in our data set. We can therefore use our data set to "train" a logistic regression model, where every individual case of some combination of specified statistics can lead to a more accurate prediction. For the sake of simplicity, we will be using Base R's glm() function to perform our logistic regression.

### Multicolinearity and Fallibilities of Logistic Regression

It is important to note that logistic regression does not come without its downsides. For example, when two predictors are highly colinear (the change in one of the variables can be explained by the change in the other), the regression model has trouble discerning the overall effect that these predictors may have in tandem, even when they may be statistically significant to predictions. This problem can compound, where many variables are multicolinear, meaning there is some set $S\in i, i = \{1,\cdots,n\}$ such that each variable in $S$ can be explained by the combination of all of the other variables in $S$. Furthermore, the computational method that Base R uses is iterative numerical optimization, which is used to estimate $\hat\beta_{MLE}$. Multicollinearity with this method can therefore lead to instability in coefficient estimates. Consequently, when values are highly colinear, the issue arises where rounding errors can worsen the overall prediction by causing the calculations propagated through the decision matrix to be absurdly high or low, effectively incorrectly reporting a variable's log odd influence. This incorrect fixing of the log odd influence coefficient can lead to such a strong prediction of the original training data that whenever you try to input new data for the model to try and "predict", we get that the model will perform more poorly. This is called overfitting, and this can dampen the prediction power of the model. In order to circumvent these issues, we will be doing some primary exploratory data analysis, as well as some well-established methods when constructing our model to avoid such clashes.

### Exploratory Data Analysis on the Potential Multicolinearity in the Data Set

In order to obtain a better understanding of the multicolinearity of our matrix,we can create a pairwise multicolinearity heatmap that displays the biggest offenders in our data.

# INSERT HEATMAP HERE!!!!!!!!!!!!!!!

Upon talking to Jordan (basketball guy), we came to the conclusion that half our dataset sucks. We will remove the suck.

## Readying the Data for Exploratory Logistic Regression Analysis

The nature of our model requires that we have valid data points to be able to perform proper regression testing (you are not able to plot null values). Due to the fact that the data set is sufficiently large, it is very likely that the data wouldn't be interpretable for the purposes mentioned above. We will view the following data to ensure the feasibility of our data set. The Kaggle data set gives us some insight about every single variable within the data set. We will refer to them here:

![](Stat184ProjectPictures/5_1cols.jpg)![](Stat184ProjectPictures/5_2cols.jpg)![](Stat184ProjectPictures/5_3cols.jpg)![](Stat184ProjectPictures/5_4cols.jpg)![](Stat184ProjectPictures/5_5cols.jpg)![](Stat184ProjectPictures/5_6cols.jpg) ![](Stat184ProjectPictures/5_7cols.jpg)![Initial Data Analysis Photos, courtesy of Kaggle.com dataset preview](Stat184ProjectPictures/5_8cols.jpg)

### Solving interpretability issues

Upon closer inspection we have found offending points that will ultimately statistically skew our data, as well as possible null values that may break our regression models and calculations in the latter processes of our analysis. Additionally, we can also see that it is extremely hard to determine what each statistic is based on their respective abbreviations. As a result, we need to go through a four step process to clean and ready the data for further analysis and testing:

-   Reject any null values that may appear in the data set, since we can not interpret them.
-   Reject any negative values from the data.
-   Rename every variable within the basketball data set to match that of the subscripted value beneath.
-   the name of the column on the website for better readability.
-   Change wins and losses to a binary 1 or 0.
-   

### Ensuring our testing variable is binary

When reviewing the game decision variable, we will notice that there are some offending values. We will therefore remove any cases where the indicator for a winning or losing team is not either "W" or "L".

# I broke this aiden :( can u help fix plz

```{r}


basketball.data <- read.csv("games.csv")
basketball.data <- fullmodel %>%
  mutate(across(everything(), ~ as.numeric(as.character(.))))
cor_matrix <- cor(basketball.data %>% select(where(is.numeric)))
cor_data <- as.data.frame(as.table(cor_matrix))
colnames(cor_data) <- c("Var1", "Var2", "Correlation")
cor_data <- cor_data %>%
  mutate(Color = ifelse(abs(Correlation) >= 0.95, "black", NA))
ggplot(cor_data, aes(Var1, Var2, fill = Correlation)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", midpoint = 0) +
  geom_tile(data = cor_data %>% filter(!is.na(Color)), aes(Var1, Var2), fill = "black") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(title = "Correlation Heatmap of Random Cases",
       x = "Variable 1",
       y = "Variable 2",
       fill = "Correlation")
```

## Assessing colinearity within our dataset

### Opponent variables

Colinearity is a pressing issue within the datascience ![](Stat184ProjectPictures/ROC_Naive.png)![](Stat184ProjectPictures/ROC_Parsimonious.png)
