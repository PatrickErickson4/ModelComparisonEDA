---
title: "Stat184Final"
author: "Patrick Erickson, Aiden Shindel, Jordan Brophy"
format: pdf
editor: visual
csl: mla.csl
bibliography: references.bib
---

# Logistic Regression Analysis for Basketball Teams: Can we Create a Robust and Parsimonious Model to Predict if one Basketball Team will Win over Another?

## Introduction

### Intuition Behind the Choice of Data Set

In basketball, a number of statistics can be used in order to predict the winner of a game. For instance, a team's field goal percentage often correlates to the number of points that a team will score in any given game. Therefore, we decided the main focus of our project: **to create a robust, interpretable model that is able to accurately predict the winning team in any case of a given match.** In order to be able to perform this kind of analysis, we must first find a data set that fits the parameters of the following:

-   The data set must be large to be able to test accurately.
-   The data set has meaningful predictors are practically relevant to our test case.
-   The data set contains a binary-interpretable winning/losing team variable (to train and test on)
-   The data set follows F.A.I.R and C.A.R.E principles.

We ultimately landed on the *NCAA Regular Season Basketball Dataset* by Nate Duncan (Kaggle), due to its extremely high case to variable ratio (90902:40), the fact that the data set had many predictors that would practically contribute to the winning or losing of a team, and that it had included a winning and losing team (binary value).

### Ethical Considerations in the Choice of our Data Set

In order to ensure the ethical feasibility of the data set, we also scrutinized our selection to follow the F.A.I.R and C.A.R.E principles as discussed in class.

Since we had obtained our data from the open-source data hub Kaggle, we can ensure that anyone can **find** and **access** this data set through Kaggle's use guidelines, stating for a free distribution of data sets that are published for public use to practice ML or data analysis on. The data is also highly versatile, taking a csv format. This is one of the most **interoperable** formats there are for data sets, especially for our use-case in R, where reading in a csv is already built into the base. Lastly, the data set can be **reused** for multiple types of data analysis, and will always remain relevant for its time period.

In terms of **collective benefit**, the data set contributes to an overall understanding of basketball without harming any individuals or teams, due to the fact that it is simply raw data. Secondly, as I had stated the author's name, there is clearly ownership over the data set, showing proper **Authority to Control**. Since proper attributions are maintained, it also falls under the **Responsibility and Ethics** guidelines of the C.A.R.E principles.

### Loading the Data Set

In conclusion, our data set satisfies all of the previously stated requirements and is therefore a suitable candidate to perform our logistical regression analysis on. Let us therefore load this data set in for further analysis:

```{r}
#| echo: false
library(tidyr)
library(ggplot2)
library(dplyr)

basketball.data <- read.csv("games.csv")
head(data,5)
```

## Data Cleaning for Interpretability

The nature of our model requires that we have valid data points to be able to perform proper regression testing (you are not able to plot null values). Due to the fact that the data set is sufficiently large, it is very likely that the data wouldn't be interpretable for the purposes mentioned above. We will view the following data to ensure the feasibility of our data set. The Kaggle data set gives us some insight about every single variable within the data set. We will refer to them here:

![](ProjectPictures/5_1cols.jpg)![](ProjectPictures/5_2cols.jpg)![](ProjectPictures/5_3cols.jpg)![](ProjectPictures/5_4cols.jpg)![](ProjectPictures/5_5cols.jpg)![](ProjectPictures/5_6cols.jpg) ![](ProjectPictures/5_7cols.jpg)![Initial Data Analysis Photos, courtesy of Kaggle.com dataset preview](ProjectPictures/5_8cols.jpg)

### Solving interpretability issues

Upon closer inspection we have found offending points that will ultimately statistically skew our data, as well as possible null values that may break our regression models and calculations in the latter processes of our analysis. This is especially within the percentage values, where we see some of the values being reported as 6300% which is obviously not feasible for the scope of these variables. Additionally, we can also see that it is extremely hard to determine what each statistic is based on their respective abbreviations. As a result, we need to go through a four step process to clean and ready the data for further analysis and testing:

-   Reject any null values that may appear in the data set, since we can not interpret them.
-   Reject any values that don't make sense (percentages over 100%, type mismatches)
-   Reject any negative values from the data
-   Rename every variable within the basketball data set to match that of the subscripted value beneath the name of the column on the website for better readability

We can utilize the following R code to accomplish these tasks:

```{r}

#remove any null values
basketball.data <- na.omit(basketball.data)

#TODO: Use visual made to refer to the data names
# underneath the columns and create a pipeline that renames ALL 40 variables to the ones mentioned in the Kaggle Dataset

#TODO: From percentages, remove any values > 1.0

#TODO: From all number values, remove numbers < 0

```

### Readying the data for logistic regression

```{r}
# 
```

## Can we predict whether a team will win or not based on the given data?

Determining whether or not the team
